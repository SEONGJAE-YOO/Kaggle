{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63a13103",
   "metadata": {},
   "source": [
    "# movie_review의 corpus data 를 sklearn을 통해 로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "033702f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_files\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a3dd67",
   "metadata": {},
   "source": [
    "# 사용할 데이터는 구글 드라이브에 올려 났습니다.\n",
    "\n",
    "[https://drive.google.com/drive/folders/1xKFDDtB8nU6D9PWO7LrP-H0G-19iPP5G?usp=sharing](https://drive.google.com/drive/folders/1xKFDDtB8nU6D9PWO7LrP-H0G-19iPP5G?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5dbec7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movietxt = \"C:/Users/MyCom/Downloads/movie_reviews/movie_reviews\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b3ee5b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_train = load_files(movietxt, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4033c7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 수\n",
    "len(movie_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb9a29cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moviedir 아래에는 neg, pos 폴더가 있다.\n",
    "movie_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8f74b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"arnold schwarzenegger has been an icon for action enthusiasts , since the late 80's , but lately his films have been very sloppy and the one-liners are getting worse . \\nit's hard seeing arnold as mr . freeze in batman and robin , especially when he says tons of ice jokes , but hey he got 15 million , what's it matter to him ? \\nonce again arnold has signed to do another expensive blockbuster , that can't compare with the likes of the terminator series , true lies and even eraser . \\nin this so cal\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  첫 번째 파일은 아놀드 슈왈제네거의 영화에 관한 것으로 보인다.\n",
    "movie_train.data[0][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b2155214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/MyCom/Downloads/movie_reviews/movie_reviews\\\\neg\\\\cv405_21868.txt'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 파일명을 가져온다. neg 폴더에 있는 파일이다.\n",
    "movie_train.filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "96f1e608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 파일은 부정적인 리뷰이며 0번째 색인이다.\n",
    "movie_train.target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fa2e1b",
   "metadata": {},
   "source": [
    "# CountVectorizer & TF-IDF 를 시도해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6887fd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "01d63302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2c2f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = ['A rose is a rose is a rose is a rose.',\n",
    "         'Oh, what a fine day it is.',\n",
    "        \"It ain't over till it's over, I tell you!!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc6f6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer의 tokenizer를 nltk의 word_tokenize를 사용하도록 변경한다.\n",
    "# 디폴트는 구두점과 불용어를 무시한다.\n",
    "# 그리고 최소 문서 빈도를 1로 설정한다.\n",
    "foovec = CountVectorizer(min_df=1, tokenizer=nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5506b0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 4,\n",
       " 'rose': 14,\n",
       " 'is': 9,\n",
       " '.': 3,\n",
       " 'oh': 12,\n",
       " ',': 2,\n",
       " 'what': 17,\n",
       " 'fine': 7,\n",
       " 'day': 6,\n",
       " 'it': 10,\n",
       " 'ai': 5,\n",
       " \"n't\": 11,\n",
       " 'over': 13,\n",
       " 'till': 16,\n",
       " \"'s\": 1,\n",
       " 'i': 8,\n",
       " 'tell': 15,\n",
       " 'you': 18,\n",
       " '!': 0}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어의 빈도수를 벡터로 바꾼다.\n",
    "sents_counts = foovec.fit_transform(sents)\n",
    "# foovec은 단어장에 고유 단어로 색인 된다.\n",
    "foovec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "72a58613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 19)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sents_counts는 3개의 문서 수와 19개의 고유 한 단어를 가진다.\n",
    "# sents는 센텐스를 의미하는 듯\n",
    "sents_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b6249c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 4, 0, 0, 0, 0, 3, 0, 0, 0, 0, 4, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [2, 1, 1, 0, 0, 1, 0, 0, 1, 0, 2, 1, 0, 2, 0, 1, 1, 0, 1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이 벡터는 작아서 볼 수 있다.\n",
    "sents_counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "73c7ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 빈도수를 카운트에 대한 값을 문서 빈도에 대한 반전 값으로 변환한다. \n",
    "# TF-IDF (Term Frequency -- Inverse Document Frequency)\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "sents_tfidf = tfidf_transformer.fit_transform(sents_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b30b050",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "TF(단어 빈도, term frequency)는 특정한 단어가 문서 내에 얼마나 자주 등장하는지를 나타내는 값으로, 이 값이 높을수록 문서에서 중요하다고 생각할 수 있다. 하지만 단어 자체가 문서군 내에서 자주 사용되는 경우, 이것은 그 단어가 흔하게 등장한다는 것을 의미한다. 이것을 DF(문서 빈도, document frequency)라고 하며, 이 값의 역수를 IDF(역문서 빈도, inverse document frequency)라고 한다. TF-IDF는 TF와 IDF를 곱한 값이다.\n",
    "\n",
    "...\n",
    "\n",
    "특정 문서 내에서 단어 빈도가 높을 수록, 그리고 전체 문서들 중 그 단어를 포함한 문서가 적을 수록 TF-IDF값이 높아진다. 따라서 이 값을 이용하면 모든 문서에 흔하게 나타나는 단어를 걸러내는 효과를 얻을 수 있다. IDF의 로그 함수값은 항상 1 이상이므로, IDF값과 TF-IDF값은 항상 0 이상이 된다. 특정 단어를 포함하는 문서들이 많을 수록 로그 함수 안의 값이 1에 가까워지게 되고, 이 경우 IDF값과 TF-IDF값은 0에 가까워지게 된다.\n",
    "\n",
    "출처 : TF-IDF - 위키백과, 우리 모두의 백과사전\n",
    "\n",
    "자주 사용 되는 단어는 오히려 별로 중요하지 않은 단어일 수도 있다. 예를 들어 조사나 this, that, is, a, the 같은 단어들, 그래서 이 값의 역수를 곱해 단어의 가중치를 주게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c51a014b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.13650997, 0.54603988,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.40952991,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.71797683,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.28969526, 0.28969526, 0.28969526,\n",
       "        0.        , 0.38091445, 0.38091445, 0.        , 0.28969526,\n",
       "        0.28969526, 0.        , 0.38091445, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.38091445, 0.        ],\n",
       "       [0.47282517, 0.23641258, 0.17979786, 0.        , 0.        ,\n",
       "        0.23641258, 0.        , 0.        , 0.23641258, 0.        ,\n",
       "        0.35959573, 0.23641258, 0.        , 0.47282517, 0.        ,\n",
       "        0.23641258, 0.23641258, 0.        , 0.23641258]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF values\n",
    "# 문서 길이에 반해 raw counts가 정규화(normalized)되어 있다.\n",
    "# 많은 문서에서 발견 되는 단어에는 가중치가 적용되어 있다.\n",
    "sents_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a21282e",
   "metadata": {},
   "source": [
    "# 실제 데이터로 돌아가기 : 영화 리뷰 변환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "583ba27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_vector 객체를 초기화 한 다음 영화 학습(train) 데이터를 벡터로 변환한다.\n",
    "# 모든 단어를 사용한다. 82%의 정확도를 가진다.\n",
    "movie_vec = CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize)\n",
    "# 상위 3000개의 단어만 사용하면78.5%의 정확도를 가진다.\n",
    "# movie_vec = CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize, max_feature=3000)\n",
    "movie_counts = movie_vec.fit_transform(movie_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9bc6c007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19604"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corpus에서 'screen'이라는 단어를 찾으면 19637번의 인덱스에 매핑되어있다.\n",
    "movie_vec.vocabulary_.get('screen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "52ebd5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19657"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비슷하게 스티븐 시걸을 찾아본다.\n",
    "movie_vec.vocabulary_.get('seagal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e3eec1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9622"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 되면 어떤 인덱스를 반환할까? 맨 앞? 맨 뒤? 랜덤?\n",
    "movie_vec.vocabulary_.get('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "22b5aace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 25280)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 엄청 크다. 2,000개의 문서와 2만5천개의 유니크한 단어들이 있다.\n",
    "movie_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fd0bf739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원래의 빈도수를 TF-IDF 값으로 바꾼다.\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "movie_tfidf = tfidf_transformer.fit_transform(movie_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "68ee1628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 25280)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변환 전과 같은 크기를 가진다. 원래의 발생 빈도 대신 tf-idf 값으로 변경 되었다.\n",
    "movie_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc00576",
   "metadata": {},
   "source": [
    "# 나이브-베이즈 분류기로 트레이닝과 테스팅\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "395118a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류기를 빌드한다.\n",
    "# Multinomial 나이브 베이즈 를 우리 모델에 사용한다.\n",
    "# 나이브 베이즈 분류로 주로 사용 되는 예제는 영화 리뷰 감성 분석, 스팸메일 필터링 등이 있다.\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9033232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트레이닝과 테스트 데이터로 나눈다.\n",
    "from sklearn.model_selection import train_test_split\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    movie_tfidf, movie_train.target, test_size = 0.20, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "91f1a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimoda 나이브 베이즈 분류기로 학습시킨다.\n",
    "clf = MultinomialNB().fit(docs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "979a0e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 셋에 대한 결과의 정확도를 예측한다.\n",
    "y_pred = clf.predict(docs_test)\n",
    "sklearn.metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ab8f5a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[175,  31],\n",
       "       [ 41, 153]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix를 만든다.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64523372",
   "metadata": {},
   "source": [
    "# 엉터리 영화리뷰에 나이브 베이즈 분류기를 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9501404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매우 짧거나 가짜 엉터리 리뷰\n",
    "reviews_new = ['This movie was excellent', 'Absolute joy ride', \n",
    "            'Steven Seagal was terrible', 'Steven Seagal shined through.', \n",
    "              'This was certainly a movie', 'Two thumbs up', 'I fell asleep halfway through', \n",
    "              \"We can't wait for the sequel!!\", '!', '?', 'I cannot recommend this highly enough', \n",
    "              'instant classic.', 'Steven Seagal was amazing. His performance was Oscar-worthy.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b61a550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 25280)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위에 있는 엉터리 리뷰를 벡터화 한다.\n",
    "reviews_new_counts = movie_vec.transform(reviews_new)\n",
    "reviews_new_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "28d5c224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 25280)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf-idf로 가중치를 주어 다시 변환한다.\n",
    "reviews_new_tfidf = tfidf_transformer.transform(reviews_new_counts)\n",
    "reviews_new_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d7451a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB Classifier Multinomial 나이브 베이즈 분류기로 예측\n",
    "# clf = MultinomialNB().fit(docs_train, y_train) \n",
    "pred = clf.predict(reviews_new_tfidf)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fbd2168a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'This movie was excellent' => pos\n",
      "'Absolute joy ride' => pos\n",
      "'Steven Seagal was terrible' => neg\n",
      "'Steven Seagal shined through.' => neg\n",
      "'This was certainly a movie' => neg\n",
      "'Two thumbs up' => neg\n",
      "'I fell asleep halfway through' => neg\n",
      "\"We can't wait for the sequel!!\" => neg\n",
      "'!' => neg\n",
      "'?' => neg\n",
      "'I cannot recommend this highly enough' => pos\n",
      "'instant classic.' => pos\n",
      "'Steven Seagal was amazing. His performance was Oscar-worthy.' => neg\n"
     ]
    }
   ],
   "source": [
    "for review, category in zip(reviews_new, pred):\n",
    "    print('%r => %s' % (review, movie_train.target_names[category]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:text_analysis]",
   "language": "python",
   "name": "conda-env-text_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
